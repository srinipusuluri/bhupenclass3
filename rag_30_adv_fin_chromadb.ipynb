{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec889d86-0d16-477f-8b7f-be03d73ad957",
   "metadata": {},
   "source": [
    "#### Overview of embeddings-based retrieval\n",
    "\n",
    "- use langchain for text splitting (chunk = chunk size of chars)\n",
    "- use sentence transformer for token splitting (chunks = number of tokens)\n",
    "- use chromadb - to store vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5536f0-651c-40e7-aa15-27ee0cda80b7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper_utils import word_wrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88f7ffe-ef6d-42d8-8f55-aa2ab8cf853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec2b161b-06af-418c-8f01-1c9e3695c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"./data/microsoft_annual_report_2022.pdf\")\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388ea1f8-1124-4f08-8f8d-c206f6cfd091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e2823e5-8b78-4f91-8115-4162713a79f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc3b3e0-ba95-4d50-868e-1f41eed51ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3748b16d-d4a7-49c3-a48a-57dcfc42acd6",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Dear shareholders, colleagues, customers, and partners:  \n",
      "We are\n",
      "living through a period of historic economic, societal, and\n",
      "geopolitical change. The world in 2022 looks nothing like \n",
      "the world in\n",
      "2019. As I write this, inflation is at a 40 -year high, supply chains\n",
      "are stretched, and the war in Ukraine is \n",
      "ongoing. At the same time, we\n",
      "are entering a technological era with the potential to power awesome\n",
      "advancements \n",
      "across every sector of our economy and society. As the\n",
      "world’s largest software company, this places us at a historic\n",
      "\n",
      "intersection of opportunity and responsibility to the world around us.\n",
      " \n",
      "Our mission to empower every person and every organization on the\n",
      "planet to achieve more has never been more \n",
      "urgent or more necessary.\n",
      "For all the uncertainty in the world, one thing is clear: People and\n",
      "organizations in every \n",
      "industry are increasingly looking to digital\n",
      "technology to overcome today’s challenges and emerge stronger. And no\n",
      "\n",
      "company is better positioned to help them than Microsoft.  \n",
      "Every day\n",
      "this past fiscal year I have had the privilege to witness our customers\n",
      "use our platforms and tools to connect \n",
      "what technology can do with\n",
      "what the world needs  it to do.  \n",
      "Here are just a few examples:  \n",
      "•\n",
      "Ferrovial, which builds and manages some of the world’s busiest\n",
      "airports and highways, is using our cloud \n",
      "infrastructure to build\n",
      "safer roads as it prepares for a future of autonomous transportation. \n",
      "\n",
      "• Peace Parks Foundation, a nonprofit helping protect natural\n",
      "ecosystems in Southern Africa, is using Microsoft \n",
      "Dynamics 365 and\n",
      "Power BI to secure essential funding, as well as our Azure AI and IoT\n",
      "solutions to help \n",
      "rangers scale their park maintenance and wildlife\n",
      "crime prevention work.  \n",
      "• One of the world’s largest robotics\n",
      "companies, Kawasaki Heavy Industries, is using the breadth of our tools\n",
      "—\n",
      "from Azure IoT and HoloLens —to create an industrial metaverse\n",
      "solution that brings its distributed workforce \n",
      "together with its\n",
      "network of connected equipment to improve productivity and keep\n",
      "employees safe.  \n",
      "• Globo, the biggest media and TV company in Brazil,\n",
      "is using Power Platform to empower its employees to \n",
      "build their own\n",
      "solutions for everything from booking sets to setting schedules.  \n",
      "•\n",
      "And Ørsted, which produces a quarter of the world’s wind energy, is\n",
      "using the Microsoft Intelligent Data \n",
      "Platform to turn data from its\n",
      "offshore turbines into insights for predictive maintenance.  \n",
      "Amid this\n",
      "dynamic environment, we delivered record results in fiscal year 2022:\n",
      "We reported $198  billion in revenue and \n",
      "$83 billion in operating\n",
      "income. And the Microsoft Cloud surpassed $100  billion in annualized\n",
      "revenue for the first time.  \n",
      "OUR RESPONSIBILITY  \n",
      "As a corporation,\n",
      "our purpose and actions must be aligned with addressing the world’s\n",
      "problems, not creating new ones. \n",
      "At our very core, we need to deliver\n",
      "innovation that helps drive broad economic growth. We, as a company,\n",
      "will do well \n",
      "when the world around us does well.  \n",
      "That’s what I\n",
      "believe will lead to widespread human progress and ultimately improve\n",
      "the lives of everyone. There is no \n",
      "more powerful input than digital\n",
      "technology to drive the world’s economic output. This is the core\n",
      "thesis for our being as a \n",
      "company, but it’s not enough. As we drive\n",
      "global economic growth, we must also commit to creating a more\n",
      "inclusive, \n",
      "equitable, sustainable, and trusted future.  \n",
      "Support\n",
      "inclusive economic growth  \n",
      "We must ensure the growth we drive reaches\n",
      "every person, organization, community, and country. This starts with\n",
      "\n",
      "increasing access to digital skills. This year alone, more than 23 \n",
      "million people accessed digital skills training as part of \n",
      "our global\n",
      "skills initiative.\n"
     ]
    }
   ],
   "source": [
    "print(word_wrap(pdf_texts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc01eee-3b6a-43bc-a3d5-5577a1687f6f",
   "metadata": {},
   "source": [
    "**RecursiveCharacterTextSplitter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d12c3a6-990a-4465-89a7-63edeea35861",
   "metadata": {},
   "source": [
    "The `RecursiveCharacterTextSplitter` is a utility that helps split long text into smaller chunks while maintaining as much context as possible. Here's how it works:\n",
    "\n",
    "##### Separators\n",
    "\n",
    "The `separators` list defines the order in which the text will be split. In this example:\n",
    "\n",
    "- It first attempts to split by two newlines (`\"\\n\\n\"`), which typically indicates a paragraph break.\n",
    "- If the chunk size condition isn't met, it moves on to split by a single newline (`\"\\n\"`), indicating line breaks or new sentences.\n",
    "- Then it tries to split by period followed by a space (`\". \"`), which indicates sentence boundaries.\n",
    "- After that, it splits by a space (`\" \"`), which breaks the text at the word level.\n",
    "- Finally, it splits by individual characters (`\"\"`) if none of the above yield a chunk that meets the size requirement.\n",
    "\n",
    "##### Chunk size and overlap\n",
    "\n",
    "- `chunk_size=1000` means that each chunk will have a maximum of 1000 characters.\n",
    "- `chunk_overlap=0` means there will be no overlap between consecutive chunks (i.e., no repeated content).\n",
    "\n",
    "##### Recursive splitting\n",
    "\n",
    "The process is recursive because it starts from the largest separator (paragraphs), and if the resulting chunk is still larger than 1000 characters, it moves down to the next smaller separator (sentences, words, etc.), ensuring that the chunks are as close to 1000 characters as possible while retaining coherent pieces of text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c938c-4899-452d-86fa-ce3121f451db",
   "metadata": {},
   "source": [
    "```python\n",
    "text = \"This is a long paragraph with multiple sentences. It discusses several topics and ideas, flowing continuously. For instance, it talks about machine learning, deep learning, and various AI applications. While doing so, it doesn’t include paragraph breaks or line breaks. Everything is packed in a single block.\"\n",
    "```\n",
    "\n",
    "##### Initial Split\n",
    "It tries to split using `\"\\n\\n\"` (paragraph breaks). There are no `\\n\\n` in this text, so no split happens.\n",
    "\n",
    "##### Next Split\n",
    "It then looks for `\"\\n\"` (line breaks). There are none here either.\n",
    "\n",
    "##### Next Split\n",
    "It tries `\". \"` (sentence breaks). Here, it successfully splits the text into three sentences:\n",
    "- \"This is a long paragraph with multiple sentences.\"\n",
    "- \"It discusses several topics and ideas, flowing continuously.\"\n",
    "- \"For instance, it talks about machine learning, deep learning, and various AI applications.\"\n",
    "- \"While doing so, it doesn’t include paragraph breaks or line breaks. Everything is packed in a single block.\"\n",
    "\n",
    "##### Final Chunks\n",
    "If any of these sentences exceed 1000 characters, it continues splitting by `\" \"` (spaces) and eventually by characters if necessary.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7054d2-cbca-425c-ac7e-5798c8f870cc",
   "metadata": {},
   "source": [
    "```python\n",
    "text = \"\"\"Data science is an interdisciplinary field that uses various techniques to extract insights from data. It involves statistics, machine learning, and data analysis.\n",
    "\n",
    "Machine learning is a subset of AI that enables systems to learn from data and improve from experience.\n",
    "\n",
    "Deep learning, a branch of machine learning, uses neural networks to model complex patterns in data.\"\"\"\n",
    "```\n",
    "\n",
    "##### Initial Split\n",
    "The first separator `\"\\n\\n\"` (paragraph breaks) will be applied:\n",
    "- \"Data science is an interdisciplinary field that uses various techniques to extract insights from data. It involves statistics, machine learning, and data analysis.\"\n",
    "- \"Machine learning is a subset of AI that enables systems to learn from data and improve from experience.\"\n",
    "- \"Deep learning, a branch of machine learning, uses neural networks to model complex patterns in data.\"\n",
    "\n",
    "##### Next Split\n",
    "If any paragraph exceeds 1000 characters, it would then try to split further using `\"\\n\"`, `\". \"`, and so on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a338ec83-6301-41a5-9ab1-e5d583306a3f",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "857b6d22-86e4-4291-93d6-7bbeae9183f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators   = [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size   = 1000,\n",
    "    chunk_overlap= 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "847d1af2-9eb7-4462-99f9-f1fbd7eeeae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c1bf90a-6f4d-4c82-ada4-4de4410c3b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 347\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "888a86f8-2fe2-4682-bdaf-c15129ed1a32",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in Xbox sales and usage. Despite \n",
      "these\n",
      "increases, we remain dedicated to achieving a net -zero future. We\n",
      "recognize that progress won’t always be linear, \n",
      "and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time.  \n",
      "On the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate \n",
      "over 1.3  million cubic meters of volumetric benefits in nine\n",
      "water basins around the world. Progress toward our zero waste\n",
      "\n",
      "commitment included diverting more than 15,200 metric tons of solid\n",
      "waste otherwise headed to landfills and incinerators, \n",
      "as well as\n",
      "launching new Circular Centers to increase reuse and reduce e -waste at\n",
      "our datacenters.  \n",
      "We contracted to protect over 17,000 acres of land\n",
      "(50% more than the land we use to operate), thus achieving our\n"
     ]
    }
   ],
   "source": [
    "print(word_wrap(character_split_texts[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa458b6-89c2-41f9-80ea-b8297a7711cc",
   "metadata": {},
   "source": [
    "#### The SentenceTransformersTokenTextSplitter\n",
    "\n",
    "The `SentenceTransformersTokenTextSplitter` is designed to split text based on token count, using tokenization principles similar to those employed by models like Sentence Transformers. Here's how it works:\n",
    "\n",
    "##### chunk_overlap=0\n",
    "This means there is no overlap between consecutive chunks. Each chunk will be entirely separate from the previous one, with no repeated content.\n",
    "\n",
    "##### tokens_per_chunk=256\n",
    "This indicates that each chunk will contain a maximum of 256 tokens. Tokens here refer to the processed units of text after tokenization, which could be words, parts of words, punctuation marks, etc., depending on the tokenizer.\n",
    "\n",
    "##### Use Case\n",
    "This splitter is typically useful when working with models that have token limits (like many transformer models), where you need to control the number of tokens being processed at a time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95f51e5-dfe8-4c6f-9370-5eb43db3a104",
   "metadata": {},
   "source": [
    "#### Two-Step Chunking Strategy: LangChain + SentenceTransformersTokenTextSplitter\n",
    "\n",
    "Chunking first with LangChain using a chunk size of 1000 characters, followed by further splitting each of those chunks using `SentenceTransformersTokenTextSplitter` with 256 tokens, provides a layered approach to ensure efficient processing for large language models. Here's how it benefits:\n",
    "\n",
    "##### 1. Balanced Chunk Sizes for Text Processing\n",
    "- **Initial Character-Based Chunking:** The initial chunking by LangChain (1000 characters) ensures that the text is divided into manageable pieces that retain context, such as paragraphs or sentences, without breaking down into excessively small parts.\n",
    "- **Token-Based Splitting for Model Constraints:** After chunking, each chunk is split further based on token limits (256 tokens per chunk) to fit within the constraints of transformer models, preventing errors during inference.\n",
    "\n",
    "##### 2. Optimized for Transformer Models\n",
    "- Transformer-based models typically have a **maximum token limit** (often 512 or 1024 tokens). By splitting into 256-token chunks, you ensure that each chunk is well within the limit, reducing the risk of truncation or cutting off important information in the middle of a chunk.\n",
    "\n",
    "##### 3. Combines Flexibility with Granularity\n",
    "- **Character-based Splitting:** Handles initial splitting by context (paragraphs, sentences) and ensures that large blocks of text are broken up in a logical way without splitting mid-word.\n",
    "- **Token-based Splitting:** Offers more **granularity** by ensuring each piece fits neatly into a model’s processing window, providing efficient model performance without losing coherence.\n",
    "\n",
    "##### 4. Improved Performance for Downstream Tasks\n",
    "- The combination of these two splitting strategies helps to balance **context retention** (larger chunks from character splitting) with **computational efficiency** (smaller chunks optimized for transformer models).\n",
    "- This is especially useful for **tasks like text embedding, summarization, and question answering**, where the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e87fbc73-9a6b-4163-a9af-207dfe9c1a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5665c695-22ea-4264-b1ac-5ba720b6d78b",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter\n",
      "expansions and the growth in xbox sales and usage. despite these\n",
      "increases, we remain dedicated to achieving a net - zero future. we\n",
      "recognize that progress won ’ t always be linear, and the rate at which\n",
      "we can implement emissions reductions is dependent on many factors that\n",
      "can fluctuate over time. on the path to becoming water positive, we\n",
      "invested in 21 water replenishment projects that are expected to\n",
      "generate over 1. 3 million cubic meters of volumetric benefits in nine\n",
      "water basins around the world. progress toward our zero waste\n",
      "commitment included diverting more than 15, 200 metric tons of solid\n",
      "waste otherwise headed to landfills and incinerators, as well as\n",
      "launching new circular centers to increase reuse and reduce e - waste\n",
      "at our datacenters. we contracted to protect over 17, 000 acres of land\n",
      "( 50 % more than the land we use to operate ), thus achieving our\n",
      "\n",
      "Total chunks: 349\n"
     ]
    }
   ],
   "source": [
    "token_split_texts = []\n",
    "\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "\n",
    "print(word_wrap(token_split_texts[10]))\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9821d43-1689-446e-90f2-221a205ba6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a13d14-4484-46f0-8e67-277337f9d138",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 4.25627157e-02,  3.32118273e-02,  3.03401388e-02, -3.48665789e-02,\n",
      "        6.84165433e-02, -8.09091479e-02, -1.54743800e-02, -1.45093317e-03,\n",
      "       -1.67444535e-02,  6.77076355e-02, -5.05413748e-02, -4.91953716e-02,\n",
      "        5.13999276e-02,  9.19272900e-02, -7.17784017e-02,  3.95196974e-02,\n",
      "       -1.28335375e-02, -2.49475036e-02, -4.62286547e-02, -2.43575107e-02,\n",
      "        3.39496396e-02,  2.55024582e-02,  2.73171254e-02, -4.12622327e-03,\n",
      "       -3.63383330e-02,  3.69086629e-03, -2.74304301e-02,  4.79670428e-03,\n",
      "       -2.88962591e-02, -1.88706890e-02,  3.66662741e-02,  2.56958492e-02,\n",
      "        3.13127823e-02, -6.39344081e-02,  5.39441109e-02,  8.22534561e-02,\n",
      "       -4.17567901e-02, -6.99577061e-03, -2.34860033e-02, -3.07479408e-02,\n",
      "       -2.97919614e-03, -7.79094175e-02,  9.35316738e-03,  3.16281826e-03,\n",
      "       -2.22570635e-02, -1.82946585e-02, -9.61250253e-03, -3.15068848e-02,\n",
      "       -5.51971514e-03, -3.27030569e-02,  1.68029740e-01, -4.74596545e-02,\n",
      "       -5.00168912e-02, -2.65963026e-03, -4.10472192e-02, -7.00394884e-02,\n",
      "        1.82959288e-02, -3.14310901e-02, -4.74112108e-02, -2.36636493e-02,\n",
      "        5.94494753e-02, -7.20144361e-02,  4.94518597e-03, -5.53269833e-02,\n",
      "        8.74548405e-02,  2.78726798e-02, -3.97725441e-02,  3.45299542e-02,\n",
      "       -9.99202579e-02,  3.28975916e-02, -5.78042828e-02,  2.45467061e-03,\n",
      "       -2.78923139e-02, -4.99470383e-02, -4.05824631e-02,  1.19175231e-02,\n",
      "        2.04190798e-02,  7.76539817e-02,  6.35161772e-02,  1.75469294e-02,\n",
      "        2.34609470e-02, -7.91659206e-03,  1.70742255e-02,  8.64122156e-03,\n",
      "       -6.81534261e-02,  3.42961513e-02,  6.46486704e-04,  2.27353964e-02,\n",
      "        5.27935922e-02, -5.85731640e-02, -9.78411436e-02, -1.47182448e-03,\n",
      "        1.37398928e-01,  2.07942631e-03, -7.58151188e-02,  5.78657649e-02,\n",
      "       -6.06963821e-02, -6.59575462e-02, -3.36505473e-02, -3.18592824e-02,\n",
      "        1.22666266e-02,  9.37330425e-02,  6.79950565e-02, -8.43403041e-02,\n",
      "        4.40247618e-02, -4.26387265e-02,  1.11630410e-02,  1.05052136e-01,\n",
      "        2.95058694e-02, -1.85210984e-02, -2.96882540e-02, -3.37703340e-02,\n",
      "        1.49671128e-03,  3.73236537e-02, -2.02497672e-02,  5.84207810e-02,\n",
      "       -3.97916101e-02, -2.12196857e-02,  6.41812617e-03, -1.02901831e-02,\n",
      "        1.96260866e-02,  3.67977913e-03, -5.03109582e-02, -1.68970581e-02,\n",
      "        4.85449620e-02,  6.68231025e-02,  1.95363741e-02,  2.72274963e-33,\n",
      "       -3.59340832e-02,  1.56618897e-02,  9.67765674e-02, -2.85153423e-04,\n",
      "       -9.76852607e-03, -9.06847343e-02,  1.44862523e-02,  1.25907622e-02,\n",
      "        2.54358873e-02, -3.44348513e-02,  4.26289625e-03,  2.71213762e-02,\n",
      "       -2.04099845e-02,  7.68848434e-02,  3.57209742e-02, -1.34925336e-01,\n",
      "        5.65785281e-02,  1.83645114e-02,  2.25778669e-02, -3.58902626e-02,\n",
      "       -1.14567466e-02, -4.99382839e-02, -1.60123259e-02, -6.33536950e-02,\n",
      "        1.04639590e-01, -8.80160555e-02, -4.46231849e-03, -1.03010312e-02,\n",
      "       -1.76307969e-02, -2.02922560e-02,  6.70421496e-03,  9.17234421e-02,\n",
      "       -7.79508008e-03,  5.94944134e-03, -1.53488982e-02,  1.82795897e-02,\n",
      "       -1.89215001e-02,  3.98753025e-02, -3.96735827e-03,  3.34193297e-02,\n",
      "       -5.60772493e-02,  7.58125558e-02, -5.62550593e-03, -5.44552766e-02,\n",
      "        6.69844076e-02, -2.59744246e-02,  1.11995526e-01, -3.64213847e-02,\n",
      "        5.01261512e-03,  3.20099257e-02,  4.96368930e-02,  9.71159562e-02,\n",
      "       -1.15469441e-01,  6.41327426e-02, -3.39788012e-02, -9.29155797e-02,\n",
      "        4.97548021e-02, -8.61341879e-02, -8.36636126e-03, -1.37037169e-02,\n",
      "       -7.88280293e-02,  1.96544304e-02, -3.71504687e-02,  1.44761698e-02,\n",
      "       -4.94030677e-02,  5.34924380e-02,  9.13901329e-02,  3.10028363e-02,\n",
      "        3.02876160e-02,  2.13427451e-02, -4.39377502e-02, -4.29743901e-02,\n",
      "       -2.26501352e-03, -2.19440777e-02,  5.47460234e-03, -1.02438796e-02,\n",
      "        2.16779914e-02, -2.73236874e-02, -7.88208446e-04,  3.30891870e-02,\n",
      "       -7.40232505e-03,  9.83002223e-03,  1.35441367e-02, -3.27448621e-02,\n",
      "        5.60191050e-02, -6.01165295e-02,  3.11219860e-02,  3.44224460e-02,\n",
      "        2.65505556e-02, -6.80791633e-03, -1.10542588e-02, -1.44399200e-02,\n",
      "        2.27853078e-02, -2.79519670e-02, -1.62089821e-02, -3.68925302e-33,\n",
      "        2.92037781e-02,  4.67048511e-02, -4.96442169e-02,  6.32448718e-02,\n",
      "        2.84380279e-02, -2.23572347e-02,  3.34798507e-02, -1.84786860e-02,\n",
      "        1.87801067e-02,  2.41163233e-03, -8.16784129e-02,  1.00841671e-01,\n",
      "        4.90231179e-02,  3.64673287e-02, -4.55603786e-02, -7.04919472e-02,\n",
      "        2.53404398e-02, -3.26794274e-02, -4.29649539e-02, -7.25101829e-02,\n",
      "        4.13071290e-02,  5.04971668e-02,  6.47718646e-03, -3.32500436e-03,\n",
      "       -8.23566839e-02,  8.00771266e-02, -3.46538685e-02,  8.47043935e-03,\n",
      "        4.13894802e-02, -1.01476572e-02, -1.02896594e-01,  4.56713475e-02,\n",
      "        1.27961040e-02, -6.01776466e-02, -2.66277846e-02, -9.72522795e-02,\n",
      "        1.57986078e-02,  7.21912757e-02, -1.53257763e-02,  1.80704822e-03,\n",
      "        6.03953265e-02, -7.07764253e-02, -2.12787557e-02, -3.85163128e-02,\n",
      "       -5.74110970e-02, -4.25381772e-03,  3.28076482e-02, -1.75956003e-02,\n",
      "        4.97576930e-02, -7.37900985e-03, -8.35457537e-03,  4.31378521e-02,\n",
      "       -5.42916134e-02,  4.31621745e-02,  2.36885641e-02,  1.81715339e-02,\n",
      "        9.28221196e-02, -4.22290061e-03, -2.25145537e-02,  1.92882754e-02,\n",
      "       -3.68443765e-02,  1.00151934e-01,  1.77647918e-02,  2.28495430e-02,\n",
      "       -3.96768413e-02,  1.68090872e-03,  5.06692007e-02,  8.56493041e-02,\n",
      "       -2.64135562e-02, -3.26686166e-02, -3.69495749e-02, -2.09940318e-02,\n",
      "        1.77660845e-02, -7.41307661e-02, -2.46881712e-02, -3.99488732e-02,\n",
      "       -2.47680545e-02, -2.41940413e-02, -1.08164595e-02,  1.08160246e-02,\n",
      "       -3.05517465e-02,  1.05193660e-01, -8.02175049e-03, -3.28962952e-02,\n",
      "        1.48043916e-01, -7.09428936e-02, -5.02191298e-02, -1.52318880e-01,\n",
      "        2.27674413e-02,  1.38459563e-01, -7.92331100e-02, -4.16010395e-02,\n",
      "       -9.37167704e-02,  6.60182908e-02,  4.35203686e-02, -4.99797110e-08,\n",
      "       -1.05480840e-02,  6.00802787e-02,  2.88234968e-02,  7.07224905e-02,\n",
      "        3.15753557e-02, -5.91379590e-02,  5.48833944e-02,  1.63166493e-01,\n",
      "        3.47594917e-02,  2.78753955e-02,  7.12676346e-02, -6.94636209e-03,\n",
      "       -5.29043190e-02,  1.16190286e-02, -2.68349759e-02,  2.89543588e-02,\n",
      "        4.34468500e-02, -7.01200590e-02, -5.87939881e-02, -3.92194353e-02,\n",
      "       -1.72939245e-02, -3.00545227e-02, -8.11252594e-02, -4.50621322e-02,\n",
      "        5.24961427e-02, -4.92357425e-02,  8.05212036e-02,  6.58550858e-02,\n",
      "       -6.08036295e-04, -4.56641577e-02,  3.05869747e-02, -6.38603978e-03,\n",
      "       -3.17557976e-02,  8.22880585e-03,  1.07610049e-02,  1.04120455e-03,\n",
      "        1.90787148e-02,  3.22798714e-02, -1.44087495e-02,  3.57979089e-02,\n",
      "       -7.22818896e-02,  3.36330086e-02,  6.66353526e-03, -1.82062685e-02,\n",
      "       -2.04362534e-02, -2.63537141e-03, -1.85477138e-01,  1.24493064e-02,\n",
      "        2.97313277e-02, -3.85484546e-02, -9.75334365e-03, -1.36943450e-02,\n",
      "        9.18333698e-03,  8.48891959e-02,  1.27218783e-01,  5.54599836e-02,\n",
      "       -4.93616238e-02, -1.19120097e-02, -5.69793135e-02,  1.04200810e-01,\n",
      "        5.71806431e-02, -1.03950515e-01, -2.37677861e-02, -2.71689966e-02],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c76f6-65e8-4641-b0cb-01df7bf0632e",
   "metadata": {},
   "source": [
    "#### Overview of `SentenceTransformerEmbeddingFunction`\n",
    "\n",
    "1. **Input Text**: \n",
    "   - The function takes input text, which can be sentences, paragraphs, or even entire documents.\n",
    "\n",
    "2. **Tokenization**: \n",
    "   - It processes the text through a Sentence Transformer model, which first tokenizes the input to handle it appropriately for embedding.\n",
    "\n",
    "3. **Embedding Generation**: \n",
    "   - The tokenized input is passed through the model to generate embeddings. Each embedding is typically a fixed-length vector that represents the semantic meaning of the text.\n",
    "\n",
    "##### Key Parameters (Example)\n",
    "\n",
    "While the implementation specifics may vary, common parameters for initializing a SentenceTransformer embedding function might include:\n",
    "\n",
    "- **model_name**: The name of the pre-trained Sentence Transformer model to use (e.g., `\"all-MiniLM-L6-v2\"`).\n",
    "- **device**: Specifies whether to run the model on CPU or GPU for faster processing.\n",
    "\n",
    "##### Benefits\n",
    "\n",
    "1. **High-Quality Embeddings**: \n",
    "   - Sentence Transformers are pre-trained on large datasets and are optimized for producing high-quality embeddings that capture nuanced semantic meanings.\n",
    "\n",
    "2. **Versatility**: \n",
    "   - The embeddings can be used in various NLP applications, including:\n",
    "   - **Semantic similarity**\n",
    "   - **Information retrieval**\n",
    "   - **Text classification**\n",
    "   - **Clustering**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe775e89-a5a1-4895-bd1c-cfc6debed073",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.get_or_create_collection(\"microsoft_annual_report_2022\", \n",
    "                                                            embedding_function = embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ba6c8c5-9ce4-44d0-9223-6fdd77871f87",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26.5 s\n",
      "Wall time: 20.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# takes time\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfdb54db-a442-423c-b006-c33a257cd7d7",
   "metadata": {
    "height": 149
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue, classified by significant product and service offerings, was\n",
      "as follows : ( in millions ) year ended june 30, 2022 2021 2020 server\n",
      "products and cloud services $ 67, 321 $ 52, 589 $ 41, 379 office\n",
      "products and cloud services 44, 862 39, 872 35, 316 windows 24, 761 22,\n",
      "488 21, 510 gaming 16, 230 15, 370 11, 575 linkedin 13, 816 10, 289 8,\n",
      "077 search and news advertising 11, 591 9, 267 8, 524 enterprise\n",
      "services 7, 407 6, 943 6, 409 devices 6, 991 6, 791 6, 457 other 5, 291\n",
      "4, 479 3, 768 total $ 198, 270 $ 168, 088 $ 143, 015 we have recast\n",
      "certain previously reported amounts in the table above to conform to\n",
      "the way we internally manage and monitor our business.\n",
      "\n",
      "\n",
      "74 note 13 — unearned revenue unearned revenue by segment was as\n",
      "follows : ( in millions ) june 30, 2022 2021 productivity and business\n",
      "processes $ 24, 558 $ 22, 120 intelligent cloud 19, 371 17, 710 more\n",
      "personal computing 4, 479 4, 311 total $ 48, 408 $ 44, 141 changes in\n",
      "unearned revenue were as follows : ( in millions ) year ended june 30,\n",
      "2022 balance, beginning of period $ 44, 141 deferral of revenue 110,\n",
      "455 recognition of unearned revenue ( 106, 188 ) balance, end of period\n",
      "$ 48, 408 revenue allocated to remaining performance obligations, which\n",
      "includes unearned revenue and amounts that will be invoiced and\n",
      "recognized as revenue in future periods, was $ 193 billion as of june\n",
      "30, 2022, of which $ 189 billion is related to the commercial portion\n",
      "of revenue. we expect to recognize approximately 45 % of this revenue\n",
      "over the next 12\n",
      "\n",
      "\n",
      "that are not sold separately. • we tested the mathematical accuracy of\n",
      "management ’ s calculations of revenue and the associated timing of\n",
      "revenue recognized in the financial statements.\n",
      "\n",
      "\n",
      "82 in addition, certain costs incurred at a corporate level that are\n",
      "identifiable and that benefit our segments are allocated to them. these\n",
      "allocated costs include legal, including settlements and fines,\n",
      "information technology, human resources, finance, excise taxes, field\n",
      "selling, shared facilities services, and customer service and support.\n",
      "each allocation is measured differently based on the specific facts and\n",
      "circumstances of the costs being allocated. segment revenue and\n",
      "operating income were as follows during the periods presented : ( in\n",
      "millions ) year ended june 30, 2022 2021 2020 revenue productivity and\n",
      "business processes $ 63, 364 $ 53, 915 $ 46, 398 intelligent cloud 75,\n",
      "251 60, 080 48, 366 more personal computing 59, 655 54, 093 48, 251\n",
      "total $ 198, 270 $ 168, 088 $ 143, 015 operating income\n",
      "\n",
      "\n",
      "47 financial statements and supplementary data income statements ( in\n",
      "millions, except per share amounts ) year ended june 30, 2022 2021 2020\n",
      "revenue : product $ 72, 732 $ 71, 074 $ 68, 041 service and other 125,\n",
      "538 97, 014 74, 974 total revenue 198, 270 168, 088 143, 015 cost of\n",
      "revenue : product 19, 064 18, 219 16, 017 service and other 43, 586 34,\n",
      "013 30, 061 total cost of revenue 62, 650 52, 232 46, 078 gross margin\n",
      "135, 620 115, 856 96, 937 research and development 24, 512 20, 716 19,\n",
      "269 sales and marketing 21, 825 20, 117 19, 598 general and\n",
      "administrative 5, 900 5, 107 5, 111 operating income 83, 383 69, 916\n",
      "52, 959 other income, net 333 1, 186 77 income before income taxes 83,\n",
      "716 71, 102 53, 036 provision for income taxes 10, 978 9, 831 8, 755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts= [query], \n",
    "                                  n_results  = 5)\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(word_wrap(document))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "377a84aa-1d93-4e97-9b2d-d59c46355338",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba0ed8ca-6640-4c09-9cb3-9de5e7cf46dc",
   "metadata": {
    "height": 336
   },
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model   = model,\n",
    "        messages= messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28bac3a2-0d29-48dc-9b48-2d9313239a25",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the year ended June 30, 2022, was $198,270\n",
      "million.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(word_wrap(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2abba-d4f5-49d5-b236-c3222f746c47",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Roles of the LLM in the RAG Function\n",
    "\n",
    "1. **Understanding Natural Language**\n",
    "   - **Interpretation of Queries**: The LLM interprets and understands user questions, grasping their meaning and intent.\n",
    "\n",
    "2. **Contextual Response Generation**\n",
    "   - **Utilizing Provided Information**: Generates responses by synthesizing the user's query with relevant information from `retrieved_documents`.\n",
    "   - **Maintaining Coherence**: Ensures responses are coherent and logically structured.\n",
    "\n",
    "3. **Inference and Knowledge Integration**\n",
    "   - **Inferring Missing Information**: Fills in gaps to create comprehensive answers based on the provided context.\n",
    "   - **Limited Contextualization**: Operates within the constraints of the given documents, avoiding external knowledge.\n",
    "\n",
    "4. **Adjusting Tone and Style**\n",
    "   - **Role-Specific Behavior**: Adjusts tone and style based on the specified role (e.g., expert financial research assistant).\n",
    "   - **Customization of Responses**: Modifies language and complexity to suit different audiences.\n",
    "\n",
    "5. **Output Generation**\n",
    "   - **Returning a Response**: Outputs the generated response for presentation to the user, ensuring quality based on the retrieved documents.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003049c-8a3f-4a9b-ba97-e4826b8dc591",
   "metadata": {
    "height": 30
   },
   "source": [
    "#### Data Processing Flow in RAG with LLM\n",
    "\n",
    "When you pass documents along with a query to a Large Language Model (LLM) hosted by a service provider, the following process occurs:\n",
    "\n",
    "##### 1. Data Transmission\n",
    "- **Sending Data**: The query and retrieved documents are sent to the LLM via an API call over the internet, typically as part of the request payload in a structured format (e.g., JSON).\n",
    "\n",
    "##### 2. Processing on the Host Machine\n",
    "- **Host Infrastructure**: The LLM resides on the service provider's servers, equipped with powerful hardware (like GPUs or TPUs) for large-scale computations.\n",
    "- **Input Handling**: The host machine receives the query and documents, processing them through various NLP algorithms such as tokenization, embedding, and attention mechanisms.\n",
    "\n",
    "##### 3. Response Generation\n",
    "- **Contextual Processing**: The LLM synthesizes the information by analyzing the query in relation to the provided documents, utilizing its training to generate a coherent response.\n",
    "- **Returning the Output**: After processing, the host machine sends the generated response back to your application via the API.\n",
    "\n",
    "##### 4. Receiving the Response\n",
    "- **Output Retrieval**: Your application receives the response and can present it to the user or perform additional processing as needed.\n",
    "\n",
    "##### Important Considerations\n",
    "- **Data Privacy**: Since documents are sent to a third-party service, consider privacy and data security, especially for sensitive or proprietary information. Adhere to relevant data protection regulations.\n",
    "- **Latency**: The time taken for the request to travel, be processed, and return can introduce latency. The actual speed depends on network conditions and processing complexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eda9bc-ae76-4db6-9e0c-ae099d852d78",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1183e75-4c65-422e-bc47-48010d8b29c9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd85cc-8898-41ed-a0aa-bd8a33fc565a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65337e9-85ee-47f7-89fd-7fe77cd0e1b2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7794092-4195-4cf3-9eab-11c9c05a26b9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cab7a1-1be7-45f0-83b7-543e48f83901",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0343be-73c9-4aed-83b0-aba09569ac87",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f3e33-e517-4f6b-8b38-c47c1e3d40b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fdcb1-57d0-4f04-af8f-7c7fc594d947",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe7893-9cbc-43c5-94ef-cbf8f5d68cf2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9524b-1085-4bdf-a161-39f11397dc1f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189f088-b58e-4583-9590-afdfa624cf87",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b26a01a-4575-446b-b8dc-a8c5ab153172",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0950575b-b69d-46a3-8c91-c7af89f5c204",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f123ad8-b2e8-4a25-8b42-a520ecaf566b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c04587-d1de-419c-a213-2e3eb67dc33d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3155972-824e-4ebe-a692-2227c113c5a8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8144a4a-85f6-4800-87f9-36a1b6ceda1f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff0b18e-12a0-4ac0-97dd-8618b22e7dbf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca7e7c-4b47-4652-9b46-a40b3dffa5e6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e7d67-7f51-41c4-8e25-edbaa02d0bd8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9188e886-d406-406f-b234-f5c3353a77a2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bb286-2694-4ed4-8466-46865e997ced",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876084b-4038-4b0c-8ec8-8294a86adfc1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac542e1-b094-431f-9611-cf7e36d3f0de",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd6114b-c09d-4173-a623-9a08aaf63e4b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10ab65-b351-4f4b-b7d2-63474acfb9f9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800f3d81-cbdb-4ba4-8d49-85747fdfded8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37847448-c9f6-4f51-bf06-f7809964a8b2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcefc87-0964-4b94-946b-2145781ad606",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc994bc-7b1e-476a-9df9-300a3e374882",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5f5d5-acb7-4b0a-93ef-e61306708e69",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4b33f-d8fb-4f3a-b884-8b43a3766583",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a480a2-2c29-4a01-80dd-ee41934b7901",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8127c2bf-0d15-4b62-b46a-f7a17ad2ec92",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ded129-a637-4269-a116-550fe9a90570",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7ee44-7b29-483f-a3f2-cc9d8e18880e",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e450dd8-9719-42c6-8c3c-33cac910e0a5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
